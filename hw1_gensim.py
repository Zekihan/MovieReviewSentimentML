import re
from random import random

import numpy as np
from gensim.models import word2vec

stop_words = ["i", "me", "my", "myself", "we", "our", "ours", "ourselves", "you", "your", "yours", "yourself",
              "yourselves", "he", "him", "his", "himself", "she", "her", "hers", "herself", "it", "its", "itself",
              "they", "them", "their", "theirs", "themselves", "what", "which", "who", "whom", "this", "that", "these",
              "those", "am", "is", "are", "was", "were", "be", "been", "being", "have", "has", "had", "having", "do",
              "does", "did", "doing", "a", "an", "the", "and", "but", "if", "or", "because", "as", "until", "while",
              "of", "at", "by", "for", "with", "about", "against", "between", "into", "through", "during", "before",
              "after", "above", "below", "to", "from", "up", "down", "in", "out", "on", "off", "over", "under", "again",
              "further", "then", "once", "here", "there", "when", "where", "why", "how", "all", "any", "both", "each",
              "few", "more", "most", "other", "some", "such", "no", "nor", "not", "only", "own", "same", "so", "than",
              "too", "very", "s", "t", "can", "will", "just", "don", "should", "now"]

REPLACE_NO_SPACE = re.compile("[.;:!\'?,\"()\[\]]")
REPLACE_WITH_SPACE = re.compile("(<br\s*/><br\s*/>)|(\-)|(\/)")
REPLACE_STOP_WORDS = re.compile(r'\b(' + r'|'.join(stop_words) + r')\b\s*')

np.random.seed(42)


def get_file_data(path):
    with open(path) as f:
        lines = f.readlines()
    text = []
    for line in lines:
        review = line[:-1]
        review = REPLACE_NO_SPACE.sub("", review.lower())
        review = REPLACE_NO_SPACE.sub(" ", review.lower())
        review = REPLACE_STOP_WORDS.sub(" ", review.lower())
        review = ' '.join([w for w in review.split() if len(w) > 1])
        text.append(review.split(' '))
    return text


data_text = get_file_data('./data/reviews.txt')
data_text.append(['<padding>','<unknown>'])
model = word2vec.Word2Vec(data_text, vector_size=200, window=5, min_count=1, workers=4)
model.save("word2vec.model")
model = word2vec.Word2Vec.load("word2vec.model")
model.train(data_text, total_examples=len(data_text), epochs=10)
model.save("word2vec.model")

vectors = model.wv
data_text.remove(['<padding>','<unknown>'])
data_text = np.asarray(data_text)
new_data = []
for text in data_text:
    new_text = []
    for word in text[:200]:
        new_text.append(vectors[word])
    for _ in range(len(new_text), 200):
        new_text.append(vectors['<padding>'])
    new_data.append(np.asarray(new_text).flatten())

def get_vector(word):
    print()

print(model.wv['high'])
a = 5
